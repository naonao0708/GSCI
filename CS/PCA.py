from __future__ import division
import pandas as pd
from matplotlib import pyplot as plt
from numpy import *
from scipy.stats import pearsonr
from sklearn.metrics import mean_squared_error, mean_absolute_error
from scipy.spatial.distance import cosine

from dl_simulation import *
from analyze_predictions import *

import spams

THREADS = 4
np.random.seed(1)  # å¯ä»¥é€‰æ‹©ä»»ä½•æ•´æ•°ä½œä¸ºç§å­


def compare_results(A, B):
    results = list(correlations(A, B, 0))[:-1]
    results += list(compare_distances(A, B))
    results += list(compare_distances(A.T, B.T))
    return results


# è®¡ç®—é€‚åº”åº¦å€¼
def calFitness_DE(X):
    n = len(X)
    fitness = 0
    for i in range(n):
        fitness += X[i] * X[i]
    return fitness


# ç”¨äºè¯„ä¼°è¾“å…¥å’Œç¨€ç–ç¼–ç æƒé‡ä¹‹é—´çš„ç›¸å…³æ€§
def calFitness(X, UW):
    n = X.shape[1]
    fitness = np.zeros((1, n))
    for i in range(n):
        fitness[0, i] = 1 - pearsonr(X[:, i], UW[:, i])[0]
    return fitness[0]


def calFitness_1(X, UW):
    return 1 - pearsonr(X, UW)[0]


# å¸¸é’è—¤ç®—æ³• (Ivy Algorithm)
def IvyAlgorithm(sizepop, Ws_tem, fitness, params):
    population = Ws_tem
    for i in range(sizepop):
        # æ‰¾åˆ°æœ€ä¼˜é‚»å±…çš„ä½ç½®
        fmin = np.min(fitness)
        fmin_arg = np.argmin(fitness)
        best_neighbor = population[fmin_arg]

        # è®¡ç®— beta å‚æ•°
        beta = (2 + np.random.rand()) / 2

        # æ›´æ–°æ¯ä¸ªä¸ªä½“çš„ä½ç½®
        if fitness[i] > fmin:  # åªæœ‰åœ¨é€‚åº”åº¦è¾ƒå·®æ—¶æ‰æ›´æ–°ä½ç½®
            population[i] = population[i] + beta * (best_neighbor - population[i]) \
                            + np.random.normal(0, 1, population[i].shape) * (best_neighbor - population[i])
    return population

# æ›´æ–°é€‰æ‹©
def selection(XTemp, XTemp1, fitnessVal, X, U):
    m, n = shape(XTemp)
    fitnessVal1 = zeros(m)
    for i in range(m):
        fitnessVal1[i] = calFitness_1(X, U.dot(XTemp1[i]))
        if (fitnessVal1[i] < fitnessVal[i]):
            for j in range(n):
                XTemp[i, j] = XTemp1[i, j]
            fitnessVal[i] = fitnessVal1[i]
    return XTemp, fitnessVal


def saveBest(fitnessVal, XTemp):
    m = shape(fitnessVal)[0]
    tmp = 0
    for i in range(1, m):
        if (fitnessVal[tmp] > fitnessVal[i]):
            tmp = i
    return fitnessVal[tmp][0], XTemp[tmp]


# è®¡ç®— MSEï¼ˆå‡æ–¹è¯¯å·®ï¼‰
def calculate_mse(original, reconstructed):
    return mean_squared_error(original, reconstructed)


# è®¡ç®— MAEï¼ˆå¹³å‡ç»å¯¹è¯¯å·®ï¼‰
def calculate_mae(original, reconstructed):
    return mean_absolute_error(original, reconstructed)


# è®¡ç®— PCCï¼ˆçš®å°”æ£®ç›¸å…³ç³»æ•°ï¼‰
def calculate_pcc(original, reconstructed):
    pcc, _ = pearsonr(original.flatten(), reconstructed.flatten())
    return pcc


# è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
def calculate_cs(original, reconstructed):
    cs = 1 - cosine(original.flatten(), reconstructed.flatten())
    return cs


def early_stopping(result_list, patience=1000, threshold=0.001):
    if len(result_list) < patience + 1:
        return False

    last_results = result_list[-patience:]
    first_result = last_results[0]
    last_result = last_results[-1]

    # âœ… æ·»åŠ å­—æ®µå­˜åœ¨æ€§æ£€æŸ¥
    required_keys = ['mse', 'mae', 'pcc', 'cs']
    if not all(k in first_result and k in last_result for k in required_keys):
        return False

    # âœ… å¤„ç†é™¤é›¶é”™è¯¯
    mse_change = abs(first_result['mse'] - last_result['mse']) / (first_result['mse'] + 1e-8)
    mae_change = abs(first_result['mae'] - last_result['mae']) / (first_result['mae'] + 1e-8)
    pcc_change = abs(first_result['pcc'] - last_result['pcc']) / (abs(first_result['pcc']) + 1e-8)
    cs_change = abs(first_result['cs'] - last_result['cs']) / (abs(first_result['cs']) + 1e-8)

    return all(change < threshold for change in [mse_change, mae_change, pcc_change, cs_change])


# ================== æ–°å¢è¯„ä¼°å‡½æ•° ==================
from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score
from scipy.sparse import issparse
import scanpy as sc
import time
import psutil


def evaluate_zero_recovery(original, reconstructed, threshold=1e-5):
    """è¯„ä¼°é›¶å€¼åŒºåŸŸæ¢å¤è´¨é‡"""
    zero_mask = (original <= threshold)
    non_zero_mask = ~zero_mask

    metrics = {
        # é›¶å€¼åŒºåŸŸæŒ‡æ ‡
        'zero_ratio_recovered': (np.abs(reconstructed[zero_mask]) < threshold).mean(),
        'zero_mae': mean_absolute_error(original[zero_mask], reconstructed[zero_mask]),
        'zero_mse': mean_squared_error(original[zero_mask], reconstructed[zero_mask]),
        'zero_pcc': pearsonr(original[zero_mask].flatten(), reconstructed[zero_mask].flatten())[0],
        'zero_cs': 1 - cosine(original[zero_mask].flatten(), reconstructed[zero_mask].flatten()),

        # éé›¶åŒºåŸŸæŒ‡æ ‡
        'non_zero_pcc': pearsonr(original[non_zero_mask].flatten(),
                                 reconstructed[non_zero_mask].flatten())[0],
        'non_zero_mae': mean_absolute_error(original[non_zero_mask], reconstructed[non_zero_mask]),
        'non_zero_mse': mean_squared_error(original[non_zero_mask], reconstructed[non_zero_mask]),
        'non_zero_cs': 1 - cosine(original[non_zero_mask].flatten(), reconstructed[non_zero_mask].flatten())
    }
    return metrics


def monitor_resource_usage():
    """ç›‘æ§èµ„æºä½¿ç”¨"""
    return {
        'time_stamp': time.strftime("%Y-%m-%d %H:%M:%S"),
        'memory_usage': psutil.Process().memory_info().rss / 1024 ** 2  # MB
    }


def load_gene_names(gene_file_path):
    """ä»txtæ–‡ä»¶åŠ è½½åŸºå› åç§°åˆ—è¡¨"""
    with open(gene_file_path, 'r') as f:
        gene_names = [line.strip() for line in f]
    return gene_names

def map_gene_indices(target_genes, all_genes):
    """å°†åŸºå› åç§°æ˜ å°„ä¸ºç´¢å¼•"""
    gene_indices = []
    for gene in target_genes:
        try:
            idx = all_genes.index(gene)
            gene_indices.append(idx)
        except ValueError:
            print(f"Warning: Gene {gene} not found in dataset")
    return gene_indices


# åœ¨evaluate_key_genes_by_nameä¸­æ·»åŠ è°ƒè¯•è¾“å‡º
def evaluate_key_genes_by_name(original, reconstructed, target_genes, all_genes):
    metrics = {}
    gene_indices = map_gene_indices(target_genes, all_genes)

    for gene, idx in zip(target_genes, gene_indices):
        orig = original[idx, :].astype(np.float64)
        recon = reconstructed[idx, :].astype(np.float64)

        # è°ƒè¯•è¾“å‡ºæ•°æ®ç»Ÿè®¡
        print(f"\n=== {gene} (idx={idx}) ===")
        print(f"åŸå§‹æ•°æ®: å‡å€¼={orig.mean():.2e} æ–¹å·®={orig.var():.2e} èŒƒå›´=[{orig.min():.2e}, {orig.max():.2e}]")
        print(f"é‡æ„æ•°æ®: å‡å€¼={recon.mean():.2e} æ–¹å·®={recon.var():.2e} èŒƒå›´=[{recon.min():.2e}, {recon.max():.2e}]")

        # æ£€æŸ¥æ–¹å·®æ˜¯å¦ä¸º0
        if orig.var() < 1e-6 or recon.var() < 1e-6:
            print(f"âš ï¸ æ–¹å·®è¿‡ä½ï¼Œæ— æ³•è®¡ç®—PCC")
            metrics[f'{gene}_pcc'] = 0.0
            continue

        # è®¡ç®—PCC
        pcc = pearsonr(orig, recon)[0]
        metrics[f'{gene}_pcc'] = pcc if not np.isnan(pcc) else 0.0

    return metrics

# ä¿®æ”¹åï¼šæ·»åŠ å¼‚å¸¸å¤„ç†
def calculate_pcc(original, reconstructed):
    try:
        pcc, _ = pearsonr(original.flatten(), reconstructed.flatten())
        return pcc if not np.isnan(pcc) else 0.0
    except:
        return 0.0
def monitor_resource_usage(start_time):
    return {
        'time_elapsed': time.time() - start_time,
        'memory_usage': psutil.Process().memory_info().rss / 1024**2
    }
def plot_gene_distribution(original, reconstructed, gene_idx):
    plt.figure(figsize=(10, 5))
    plt.scatter(original[gene_idx, :], reconstructed[gene_idx, :], alpha=0.3)
    plt.xlabel("Original Expression")
    plt.ylabel("Reconstructed Expression")
    plt.title(f"Gene {gene_idx} Distribution")
    plt.show()
# åœ¨ç”Ÿæˆxaåçš„è¯„ä¼°éƒ¨åˆ†
def main_evaluation(z, xa, all_genes, target_genes):
    start_time = time.time()
    """æ•´åˆæ‰€æœ‰è¯„ä¼°æŒ‡æ ‡"""
    metrics = {}
    # æ‰“å°å‰5ä¸ªç›®æ ‡åŸºå› çš„ç´¢å¼•å’Œåç§°
    gene_indices = map_gene_indices(target_genes, all_genes)
    print("å…³é”®åŸºå› ç´¢å¼•ç¤ºä¾‹ï¼š")
    for gene, idx in zip(target_genes[:5], gene_indices[:5]):
        print(f"{gene}: ç´¢å¼•={idx}")

    # åŸºç¡€æ•°å€¼æŒ‡æ ‡
    metrics['mse'] = mean_squared_error(z, xa)
    metrics['mae'] = mean_absolute_error(z, xa)
    metrics['pcc'] = calculate_pcc(z, xa)
    # metrics['pcc'] = pearsonr(z.flatten(), xa.flatten())[0]
    metrics['cs'] = 1 - cosine(z.flatten(), xa.flatten())

    # é›¶å€¼æ¢å¤ä¸“é¡¹
    metrics.update(evaluate_zero_recovery(z, xa))

    # # ç”Ÿç‰©å­¦èšç±»ä¸€è‡´æ€§
    # metrics.update(biological_consistency(z, xa))

    # å…³é”®åŸºå› è¯„ä¼°
    metrics.update(evaluate_key_genes_by_name(z, xa, target_genes, all_genes))

    # èµ„æºç›‘æ§
    metrics.update(monitor_resource_usage(start_time))
    # åœ¨main_evaluationä¸­æ·»åŠ æ•°æ®ç»Ÿè®¡
    print(f"åŸå§‹æ•°æ®éé›¶å€¼æ¯”ä¾‹: {np.mean(z > 1e-5):.2%}")
    print(f"é‡æ„æ•°æ®éé›¶å€¼æ¯”ä¾‹: {np.mean(xa > 1e-5):.2%}")
    # åœ¨è¯„ä¼°å‡½æ•°ä¸­è°ƒç”¨
    plot_gene_distribution(z, xa, 16913)  # BRCA1çš„ç´¢å¼•
    return metrics


# ================== åœ¨ metrics è®¡ç®—åæ·»åŠ  ==================
def print_iteration_summary(gen, metrics):
    """æ ¼å¼åŒ–æ‰“å°å½“å‰è¿­ä»£ç»“æœ"""
    # åŸºç¡€æŒ‡æ ‡
    print(f"\n=== Iteration {gen + 1} ===")
    print(f"  MSE      : {metrics.get('mse', 0):.4e}")
    print(f"  MAE      : {metrics.get('mae', 0):.4e}")
    print(f"  PCC      : {metrics.get('pcc', 0):.4f}")
    print(f"  CS       : {metrics.get('cs', 0):.4f}")

    # å…³é”®ç”Ÿç‰©æŒ‡æ ‡
    print("  --- Biological Metrics ---")
    print(f"  Clustering ARI : {metrics.get('clustering_ari', 0):.4f}")

    # å…³é”®åŸºå› è¡¨ç°ï¼ˆè‡ªåŠ¨ç­›é€‰æ‰€æœ‰ä»¥_pccç»“å°¾çš„æŒ‡æ ‡ï¼‰
    pcc_genes = {k: v for k, v in metrics.items() if k.endswith('_pcc')}
    for gene, val in pcc_genes.items():
        print(f"  {gene.split('_')[0]:<8} : {val:.4f}")

    # èµ„æºä½¿ç”¨
    print("  --- Resource Usage ---")
    print(f"  Memory (MB) : {metrics.get('memory_usage', 0):.1f}")
    print(f"  Time (s)    : {time.time() - metrics.get('start_time', 0):.1f}")


# ================== æ–°å¢é™ç»´æ¨¡å— ==================
from sklearn.decomposition import PCA, FastICA, NMF, TruncatedSVD, FactorAnalysis, KernelPCA, SparsePCA
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis

from scipy import sparse

# ================== æ–°å¢å·¥å…·å‡½æ•° ==================
def fortranify(X):
    """âœ… ä¿®æ”¹1ï¼šå¼ºåˆ¶è½¬æ¢ä¸ºFortranæ ¼å¼ + float64"""
    if sparse.issparse(X):
        return X.astype(np.float64).tocsc()
    else:
        return np.asfortranarray(X.astype(np.float64))
class LinearDimReductor:
    # """æ”¯æŒ8ç§çº¿æ€§é™ç»´æ–¹æ³•çš„ç»Ÿä¸€æ¥å£"""
    #
    # def __init__(self, method='pca', n_components=20):
    #     self.method = method.lower()
    #     self.n_components = n_components
    #     self.model = None
    #     self.shape_ = None  # è®°å½•åŸå§‹æ•°æ®å½¢çŠ¶
    #
    # def _validate_data(self, X):
    #     """ç»Ÿä¸€æ•°æ®æ ¼å¼ä¸º (features, samples)"""
    #     if X.shape[0] < X.shape[1]:
    #         return X.T
    #     return X
    #
    # def fit_transform(self, X):
    #     """æ‰§è¡Œé™ç»´ï¼Œè¿”å› (n_components, samples)"""
    #     X = self._validate_data(X)
    #     self.shape_ = X.shape
    #
    #     try:
    #         if self.method == 'pca':
    #             self.model = PCA(n_components=self.n_components)
    #             reduced = self.model.fit_transform(X.T).T
    #
    #         elif self.method == 'ica':
    #             self.model = FastICA(n_components=self.n_components, random_state=0)
    #             reduced = self.model.fit_transform(X.T).T
    #
    #         elif self.method == 'nmf':
    #             # å¤„ç†è´Ÿå€¼é—®é¢˜
    #             X_shifted = X - np.min(X) + 1e-6
    #             self.model = NMF(n_components=self.n_components,
    #                              init='nndsvd',
    #                              max_iter=1000,
    #                              beta_loss='kullback-leibler')
    #             W = self.model.fit_transform(X_shifted)
    #             reduced = self.model.components_
    #             return fortranify(reduced)
    #
    #         elif self.method == 'svd':
    #             self.model = TruncatedSVD(n_components=self.n_components)
    #             reduced = self.model.fit_transform(X.T).T
    #
    #         elif self.method == 'factor':
    #             self.model = FactorAnalysis(n_components=self.n_components)
    #             reduced = self.model.fit_transform(X.T).T
    #
    #         elif self.method == 'kernel_pca':
    #             self.model = KernelPCA(n_components=self.n_components, kernel='rbf')
    #             reduced = self.model.fit_transform(X.T).T
    #
    #         elif self.method == 'lda':
    #             # éœ€è¦ä¼ªæ ‡ç­¾ï¼Œä½¿ç”¨èšç±»ç”Ÿæˆ
    #             from sklearn.cluster import KMeans
    #             pseudo_labels = KMeans(n_clusters=2).fit_predict(X.T)
    #             self.model = LinearDiscriminantAnalysis(n_components=self.n_components)
    #             reduced = self.model.fit_transform(X.T, pseudo_labels).T
    #
    #         elif self.method == 'sparse_pca':
    #             self.model = SparsePCA(n_components=self.n_components, alpha=0.5)
    #             reduced = self.model.fit_transform(X.T).T
    #
    #         else:
    #             raise ValueError(f"ä¸æ”¯æŒçš„é™ç»´æ–¹æ³•: {self.method}")
    #
    #         return reduced.astype(np.float32)
    #
    #     except Exception as e:
    #         print(f"{self.method} é™ç»´å¤±è´¥: {str(e)}")
    #         return X  # è¿”å›åŸå§‹æ•°æ®ä½œä¸ºfallback
    #
    # def inverse_transform(self, reduced):
    #     """é€†å˜æ¢å›åŸå§‹ç‰¹å¾ç©ºé—´"""
    #     if self.model is None:
    #         return reduced
    #
    #     try:
    #         if self.method in ['pca', 'ica', 'svd', 'factor', 'lda','sparse_pca','kernel_pca','nmf']:
    #             return self.model.inverse_transform(reduced.T).T
    #
    #         elif self.method == 'nmf':
    #             return self.model.components_.T @ reduced
    #
    #         elif self.method == 'kernel_pca':
    #             print("è­¦å‘Š: KernelPCAæ— ç²¾ç¡®é€†å˜æ¢ï¼Œä½¿ç”¨è¿‘ä¼¼é‡æ„")
    #             from sklearn.linear_model import LinearRegression
    #             reg = LinearRegression().fit(self.model.transform(X.T), X.T)
    #             return reg.predict(reduced.T).T
    #
    #         elif self.method == 'sparse_pca':
    #             return self.model.inverse_transform(reduced.T).T
    #
    #         else:
    #             return reduced
    #
    #     except AttributeError:
    #         return reduced
    """âœ… ä¿®æ”¹2ï¼šç®€åŒ–é™ç»´ç±»ï¼Œç¡®ä¿è¾“å…¥è¾“å‡ºç»´åº¦ä¸€è‡´"""

    def __init__(self, method='pca', n_components=20):
        self.method = method.lower()
        self.n_components = n_components
        self.model = None

    def fit_transform(self, X):
        """è¾“å…¥è¾“å‡ºå½¢çŠ¶ï¼š(features, samples) -> (components, samples)"""
        try:
            if self.method == 'pca':
                self.model = PCA(n_components=self.n_components)
                return self.model.fit_transform(X.T).T.astype(np.float64)
            elif self.method == 'nmf':
                self.model = NMF(n_components=self.n_components, init='nndsvd')
                return self.model.fit_transform(X.T).T.astype(np.float64)
            else:
                raise ValueError(f"Unsupported method: {self.method}")
        except Exception as e:
            print(f"{self.method}é™ç»´å¤±è´¥: {str(e)}")
            return X.astype(np.float64)

    def inverse_transform(self, reduced):
        if self.method == 'pca':
            # âœ… æ­£ç¡®çš„é€†å˜æ¢ï¼ˆç§»é™¤é”™è¯¯ç¨€ç–åŒ–ï¼‰
            return self.model.inverse_transform(reduced.T).T.astype(np.float64)
        elif self.method == 'nmf':
            return (self.model.components_ @ reduced).astype(np.float64)
        return reduced

# ================== æ–°å¢åŠŸèƒ½ï¼šèµ„æºç›‘æ§ ==================
from run_smaf import smaf
if __name__ == "__main__":
    # SMAF setting
    biased_training = 0.  # åç½®
    composition_noise = 0.  # å™ªå£°
    subset_size = 0  # å­é›†å¤§å°
    measurements = 400  # æµ‹é‡çš„æ•°é‡
    sparsity = 10  # ç¨€ç–åº¦
    dictionary_size = 0.5  # å­—å…¸å¤§å°
    training_dictionary_fraction = 0.05  # è®­ç»ƒå­—å…¸æ¯”ä¾‹
    SNR = 2.0  # ä¿¡å™ªæ¯”
    ####################å¢åŠ ##############################
    best_mse = float('inf')  # åˆå§‹åŒ–æœ€ä½³MSE
    best_mae = float('inf')  # åˆå§‹åŒ–æœ€ä½³MAE
    best_pcc = float('-inf')  # åˆå§‹åŒ–æœ€ä½³PCC
    best_cs = float('-inf')  # åˆå§‹åŒ–æœ€ä½³CS
    early_stop_counter = 0  # ç”¨äºè®°å½•æ—©åœçš„è¿­ä»£æ¬¡æ•°
    early_stop_patience = 1000  # è®¾å®šè€å¿ƒå€¼ï¼Œè¶…è¿‡è¯¥æ¬¡æ•°æ²¡æœ‰æ”¹è¿›å°±åœæ­¢
    result1 = []  # ç”¨äºä¿å­˜æ¯è½®çš„ç»“æœ
    result2 = []  # ç”¨äºä¿å­˜æ¯è½®çš„ç»“æœ

    # æ•°æ®åŠ è½½
    # x = np.load("./Data/GSE123358/GSE123358_log.npy")
    # x = np.load("./Data/GSE124989/GSE124989_log.npy")
    x = np.load("./Data/GSE123358/GSE123358_VAE+GAN1.npy")
    # x = np.load("./Data/GSE124989/results/GSE124989_VAE-GAN.npy")
    # x = np.load("./Result/GSE147326/GSE147326_VAE+GAN.npy")
    # x = np.load("./Data/GSE147326/results/recovered_data.npy")
    # x = np.load("./Data/GSE147326/GSE147326_log.npy")
    # x = np.load("./Data/GSE271269/GSE271269_VAE+GAN1.npy")
    x = x.astype(np.float64)
    # z = np.load("./Data/GSE123358/GSE123358_VAE+GAN1.npy")
    z = np.load("./Data/GSE123358/GSE123358_log.npy")
    # z = np.load("./Data/GSE124989/GSE124989_log.npy")
    # z = np.load("./Data/GSE147326/results/recovered_data.npy")
    # z = np.load("./Data/GSE271269/GSE271269_log.npy")
    # z = np.load("./Data/GSE124989/GSE124989_log.npy")
    z = z.astype(np.float64)

    print(f"åŸå§‹æ•°æ®å½¢çŠ¶: {x.shape}")
    print(f"åŸå§‹æ•°æ®å½¢çŠ¶: {z.shape}" )

    # åŠ è½½åŸºå› åç§°
    all_genes = load_gene_names("./Data/GSE123358/gene.txt")  # åŸå§‹æ•°æ®åŸºå› åç§°
    # all_genes = load_gene_names("./Data/GSE124989/gene.txt")  # åŸå§‹æ•°æ®åŸºå› åç§°
    target_genes = ['BRCA1', 'BRCA2', 'BARD1', 'BRIP1', 'PALB2', 'RAD51', 'RAD54L', 'XRCC3', 'ERBB2', 'ESR1', 'PGR',
                        'PIK3CA', 'TP53', 'PPM1D', 'RB1CC1', 'HMMR', 'NQO2', 'SLC22A18', 'PTEN', 'EGFR', 'KIT', 'NOTCH1',
                        'FZD7', 'LRP6', 'FGFR1', 'CCND1']
    print(f"å…³é”®åŸºå› åŒ¹é…æƒ…å†µ: {len(map_gene_indices(target_genes, all_genes))}/{len(target_genes)}")

    # å®éªŒå‚æ•°ï¼ˆæ–°å¢ï¼‰
    METHODS = ['pca',  'nmf', 'none']  # 'none'è¡¨ç¤ºä¸é™ç»´
    N_COMPONENTS = 20
    MAX_ITER = 100

    # ================== ä¿®å¤åçš„ä¸»å¾ªç¯ ==================
    for method in METHODS:
        print(f"\n=== å½“å‰æ–¹æ³•: {method.upper()} ===")

        # --- æ•°æ®é¢„å¤„ç† ---
        if method != 'none':
            reductor = LinearDimReductor(method, N_COMPONENTS)
            processed_x = fortranify(reductor.fit_transform(x))
            print(f"âœ… é™ç»´éªŒè¯ {x.shape} -> {processed_x.shape}")
        else:
            processed_x = fortranify(x)

        # --- ç®—æ³•åˆå§‹åŒ– ---
        k = min(int(processed_x.shape[1] * 3), 120)
        NP = 40
        Ws = np.zeros((NP, k, processed_x.shape[1]))
        UW = (np.random.randn(processed_x.shape[0], k).astype(np.float64),
              np.random.randn(k, processed_x.shape[1]).astype(np.float64))

        # --- SMAFåˆå§‹åŒ– ---
        try:
            UF, WF = smaf(processed_x, k, 5, 0.0001, maxItr=10,
                          UW=UW, donorm=True, mode=1, mink=3.)
            print(f"âœ… SMAFåˆå§‹åŒ–æˆåŠŸ UF={UF.shape}, WF={WF.shape}")
        except Exception as e:
            print(f"âŒ SMAFå¤±è´¥: {str(e)}")
            continue

        # --- ä¸»ä¼˜åŒ–å¾ªç¯ ---
        maxItr = 100
        fitnessVal = np.zeros((NP, processed_x.shape[1]))

        from tqdm import tqdm

        for gen in tqdm(range(maxItr), desc=f"{method.upper()} ä¼˜åŒ–è¿›åº¦"):
            # 1. æ›´æ–°æ¯ä¸ªæ ·æœ¬çš„æƒé‡
            for i in range(processed_x.shape[1]):  # éå†æ¯ä¸ªæ ·æœ¬
                Ws_tem = Ws[:, :, i]

                # --- IVYç®—æ³•æ›´æ–° ---
                fa = IvyAlgorithm(NP, Ws_tem, fitnessVal[:, i], [1.0, 1.0])
                Ws_tem, fitnessVal[:, i] = selection(
                    Ws_tem, fa, fitnessVal[:, i],
                    processed_x[:, i], UF
                )

                # ä¿å­˜æœ€ä½³æƒé‡
                best_idx = np.argmin(fitnessVal[:, i])
                WF[:, i] = Ws_tem[best_idx]
                Ws[:, :, i] = Ws_tem

            # 2. æ›´æ–°å­—å…¸
            UF = spams.lasso(
                fortranify(processed_x.T),
                D=fortranify(WF.T),
                lambda1=0.0005 * (np.linalg.norm(processed_x) ** 2 / processed_x.shape[1]),
                mode=1,
                numThreads=4
            )
            UF = np.asarray(UF.todense()).T.astype(np.float64)

            # 3. é‡å»ºæ•°æ®
            xa_lowdim = UF.dot(WF)
            if method != 'none':
                xa = reductor.inverse_transform(xa_lowdim)
                assert xa.shape == x.shape, f"âŒ ç»´åº¦ä¸åŒ¹é… {xa.shape} vs {x.shape}"
            else:
                xa = xa_lowdim

            # 4. æ¯10æ¬¡è¿­ä»£æ‰“å°è¿›åº¦
            if (gen + 1) % 10 == 0:
                print(f"\n--- Iteration {gen + 1}/{maxItr} ---")
                print(f"å½“å‰é‡å»ºç»´åº¦: {xa.shape}")
                metrics = main_evaluation(z, xa, all_genes, target_genes)
                print_iteration_summary(gen, metrics)

                # 5. æ—©åœæ£€æµ‹
                # âœ… ç¡®ä¿è®°å½•æ‰€æœ‰å¿…è¦å­—æ®µ
                metrics = main_evaluation(z, xa, all_genes, target_genes)
                result1.append({
                    'iteration': gen + 1,
                    'mse': metrics['mse'],
                    'mae': metrics['mae'],
                    'pcc': metrics['pcc'],
                    'cs': metrics['cs']
                })

                if early_stopping(result1, patience=50):
                    print(f"ğŸ æ—©åœè§¦å‘äºç¬¬ {gen + 1} æ¬¡è¿­ä»£")
                    break

        # --- æœ€ç»ˆè¯„ä¼° ---
        final_metrics = main_evaluation(z, xa, all_genes, target_genes)
        print("\n=== æœ€ç»ˆç»“æœ ===")
        print_iteration_summary(gen, final_metrics)
        np.savetxt(f'./Result/GSE123358/GSE123358_{method}+PCA.csv', xa, delimiter=',')

    # --- ä¿å­˜æ‰€æœ‰ç»“æœ ---
    pd.DataFrame(result1).to_csv("D://TCGA-BRCA//DeepCS//Result//GSE123358//123358_PCA-IVYCS.csv", index=False)



